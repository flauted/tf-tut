{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A TensorFlow Input Pipeline Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to write Celeba images and male-female labels (available [here](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)) into a TFRecords file. Then, use the Dataset API to load the information into the graph. We will use a CNN to determine the gender of the image. We want TensorBoard visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylan/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread  # There are others that would work here.\n",
    "from cv2 import resize  # Again, others to choose from.\n",
    "import os  # Tools to read data off disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Paths and Labels from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labeled_image_list(\n",
    "        img_dir=\"/media/dylan/DATA/img_align_celeba\",\n",
    "        label_txt_path=\"/media/dylan/DATA/list_attr_celeba.txt\"):\n",
    "    \"\"\"Read labeled images off disk.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: Path to folder containing all the images.\n",
    "        label_txt_path: Full path to annotation txt file.\n",
    "        \n",
    "    Returns:\n",
    "        A list of image paths for all images.\n",
    "        A list of one-hot lists [male?, female?] for all images.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the image paths.\n",
    "    img_filenames = os.listdir(img_dir)\n",
    "    # This is a list.\n",
    "    abs_img_paths = [os.path.join(img_dir, img_f) \n",
    "                     for img_f in img_filenames]\n",
    "    \n",
    "    # Get the labels by \"r\"eading the txt.\n",
    "    with open(label_txt_path, \"r\") as f:\n",
    "        img_fnames_and_lbls = f.read().splitlines()\n",
    "    # We will make a one-hot list-of-lists for all imgs.\n",
    "    labels = []\n",
    "    for fname_and_lbl in img_fnames_and_lbls[2:]:  # Skip 2 header rows\n",
    "        # Take everything after the .jpg part\n",
    "        lbl_str = fname_and_lbl.split(\".jpg\")[1]\n",
    "        lbl_str_split = lbl_str.split(\" \")\n",
    "        all_labels = [int(label) \n",
    "                      for label in lbl_str_split if label is not \"\"]\n",
    "        # Now we have a list of all 40 attributes,\n",
    "        # we want male info\n",
    "        is_male = all_labels[20] == 1\n",
    "        labels.append([int(is_male), int(not is_male)])\n",
    "    return abs_img_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make TFRecords\n",
    "We invoke the function we just defined to get all the image paths and labels. For each path and label, write the TFR format data into a file located at `tfr_file`.\n",
    "\n",
    "NOTE that in this example `TFRecordWriter` expects the `tfr` folder to **already exist** on **some systems** (for instance, I think `TFRecordWriter` can create the directory on Windows, but I know it cannot on Linux.) HOWEVER, it **creates** a file called `celeba_tutorial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tfr(\n",
    "        all_image_paths, all_labels, tfr_file=\"tfr/celeba_tutorial\"):\n",
    "    \"\"\"Write a TFR file inside `tfr_dir`.\n",
    "    \n",
    "    Get all the image paths and labels. Recall the labels come in\n",
    "    a list of lists of ints. FOR EACH IMAGE/LABEL, read the image, \n",
    "    do any preprocessing while image is still np.ndarray, \n",
    "    and convert into `bytes`. Then construct an `Example` object. \n",
    "    The `Example` object contains a `tf.train.Features` object\n",
    "    with a dictionary of `features`. We use helper functions\n",
    "    to convert our data into `Feature` types. Then, we write the image\n",
    "    and label to the file.\n",
    "    \n",
    "    COMMON GOTCHA: `bytes`, the raw encoding for the image, \n",
    "    is not a list type. However, `tf.train.Feature` needs a list!\n",
    "    That's why `_bytes_feature` turns `value` into a list. On the\n",
    "    other hand, each label **is** an integer list! So, we do **not** \n",
    "    need to make the argument of `_int64_list_feature` a list! \n",
    "    \n",
    "    \"\"\"\n",
    "    def _int64_list_feature(a_list):\n",
    "        return tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=a_list))\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    print(\"Writing TFR files.\")\n",
    "    writer = tf.python_io.TFRecordWriter(tfr_file)\n",
    "    for n, (path, label) in enumerate(zip(all_image_paths, all_labels)):\n",
    "        # n is only for a nice little status bar.\n",
    "        print(\"Writing file {}\\r\".format(n), end=\"\")\n",
    "        disk_im = imread(path)  # numpy ndarray, 218 x 178 x 3\n",
    "        resized_im = resize(disk_im, (128, 128))  # np, 128 x 128 x 3\n",
    "        raw_im = resized_im.tostring()  # <class 'bytes'>\n",
    "        # Construct an example proto-obj,\n",
    "        example = tf.train.Example(\n",
    "            # which wants a Features proto-obj,\n",
    "            features=tf.train.Features(\n",
    "                # which wants a dict.\n",
    "                feature={\n",
    "                    'image_raw': _bytes_feature(raw_im),\n",
    "                    'label': _int64_list_feature(label)\n",
    "        })) # close your example object\n",
    "        serialized = example.SerializeToString()\n",
    "        writer.write(serialized)\n",
    "    print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to implement some simple overwrite protection\n",
    "# because it takes a while to write all of celeba, even to SSD.\n",
    "\n",
    "write_tfr = False  # force overwrite. Reset it while you're waiting :)\n",
    "TFR_FILE = \"/media/dylan/DATA/tfr/celeba_tutorial\"\n",
    "\n",
    "if write_tfr or not os.path.isfile(TFR_FILE):\n",
    "    all_image_paths, all_labels = read_labeled_image_list()\n",
    "    make_tfr(all_image_paths, all_labels, tfr_file=TFR_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want a train/test split? Do something like\n",
    "\n",
    "    import sklearn.model_selection as sk\n",
    "    TFR_TRAIN = \"tfr/celeba_train\"\n",
    "    TFR_TEST = \"tfr/celeba_test\"\n",
    "    \n",
    "    if write_tfr or not os.path.isfile(TFR_FILE):\n",
    "        all_image_paths, all_labels = read_labeled_image_list()\n",
    "        tr_paths, te_paths, tr_lbls, te_lbls = sk.train_test_split(\n",
    "            all_image_paths, all_labels, test_size=0.2)\n",
    "        make_tfr(tr_paths, tr_lbls, tfr_file=TFR_TRAIN)\n",
    "        make_tfr(te_paths, te_lbls, tfr_file=TFR_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Now we have a data file to read. Let's get to the graph building. The first part of any graph is the data input pipeline. We're going to make\n",
    "an `input_pipeline` function. Why a function? If we want to use a train-test split, we want a dataset for both TFR files. We would call `input_pipeline` twice - once with `TFR_TRAIN` and again with `TFR_TEST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_pipeline(batch_size, epochs, tfr_file=\"tfr/celeba_tutorial\"):\n",
    "    dataset = tf.data.TFRecordDataset(tfr_file)\n",
    "\n",
    "    def parse_protocol_buffer(example_proto):\n",
    "        \"\"\"Read the TFR file into TENSORS! Read the bytes image\n",
    "        into a tf.string tensor and read the label into a\n",
    "        tf.int64 tensor!\"\"\"\n",
    "        features = {'image_raw': tf.FixedLenFeature((), tf.string),\n",
    "                    # NOTICE THE 2 HERE!\n",
    "                    'label': tf.FixedLenFeature((2), tf.int64)}\n",
    "        parsed_features = tf.parse_single_example(\n",
    "            example_proto, features)\n",
    "        return parsed_features['image_raw'], parsed_features['label']\n",
    "\n",
    "    # Apply the reading function to the dataset.\n",
    "    dataset = dataset.map(parse_protocol_buffer)\n",
    "\n",
    "    def convert_parsed_proto_to_input(image_string, label):\n",
    "        \"\"\"Convert that tf.string tensor with the raw image\n",
    "        into a tf.uint8 tensor (natural data-type for disk imgs).\n",
    "        Then restore the image shape. Finally, turn it into\n",
    "        a float so we can do real-valued math to it.\"\"\"\n",
    "        image_decoded = tf.decode_raw(image_string, tf.uint8)\n",
    "        image_resized = tf.reshape(image_decoded, (128, 128, 3))\n",
    "        image = tf.cast(image_resized, tf.float32)\n",
    "        # Reshape label as a sanity check, convert to a real number.\n",
    "        label = tf.reshape(label, [2])\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        # I usually put my image elements in [-1, 1]\n",
    "        return image * (2. /255) -1, label\n",
    "\n",
    "    # Apply the decoding function to the dataset.\n",
    "    dataset = dataset.map(convert_parsed_proto_to_input)\n",
    "    # Shuffle the dataset.\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    # Fill the dataset with this many examples & labels\n",
    "    dataset = dataset.repeat(batch_size*epochs)\n",
    "    # Collect `batch_size` num. of elements. Image and label\n",
    "    # tensors in the dataset change from [128 x 128 x 3] \n",
    "    # and [2] into [bs x 128 x 128 x 3] and [bs x 2].\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Fill the dataset with this many batches!\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_OUTPUT_SIZE = 2  # This is num labels per img. MALE and FEMALE\n",
    "\n",
    "def conv(imgs, filters_out, stride_size, kernel_size):\n",
    "    \"\"\"Simple 2D convolution helper function.\"\"\"\n",
    "    filters_in = imgs.get_shape().as_list()[3]\n",
    "    Kernel = tf.get_variable(\n",
    "        \"kernel\",\n",
    "        [kernel_size[0], kernel_size[1], filters_in, filters_out],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    Bias = tf.get_variable(\n",
    "        \"bias\",\n",
    "        [filters_out],\n",
    "        initializer=tf.zeros_initializer())\n",
    "    evidence = tf.nn.conv2d(\n",
    "        imgs,\n",
    "        Kernel,\n",
    "        strides=[1, stride_size[0], stride_size[1], 1],\n",
    "        padding=\"SAME\")\n",
    "    return evidence + Bias\n",
    "\n",
    "def model(image_tensor, keep_prob=0.5):\n",
    "    # Since conv uses tf.get_variable, we NEED tf.variable_scope.\n",
    "    # That tells tf.get_variable what variable to get, i.e. a new\n",
    "    # one or one that already exists. tf.variable_scope otherwise\n",
    "    # behaves similarly to tf.name_scope\n",
    "    with tf.variable_scope(\"layer1\"):\n",
    "        # input: bs x 128 x 128 x 3\n",
    "        z1 = conv(image_tensor, 16, (2, 2), (5, 5))\n",
    "        a1 = tf.nn.relu(z1)\n",
    "    with tf.variable_scope(\"layer2\"):\n",
    "        # input: bs x 64 x 64 x 16\n",
    "        z2 = conv(a1, 32, (2, 2), (5, 5))\n",
    "        a2 = tf.nn.relu(z2)\n",
    "    # let's max-pool to hurry things up\n",
    "    m2 = tf.nn.max_pool(a2, [1, 2, 2, 1], [1, 2, 2, 1], \"SAME\")\n",
    "    with tf.variable_scope(\"layer3\"):\n",
    "        # input: bs x 16 x 16 x 32\n",
    "        z3 = conv(m2, 64, (2, 2), (5, 5))\n",
    "        a3 = tf.nn.relu(z3)\n",
    "    with tf.variable_scope(\"layer4\"):\n",
    "        # input: bs x 8 x 8 x 64\n",
    "        z4 = conv(a3, 64, (2, 2), (5, 5))\n",
    "        a4 = tf.nn.relu(z4)\n",
    "        # output: bs x 4 x 4 x 64\n",
    "        \n",
    "    # Let's quit convolving.\n",
    "    final_shape = a4.get_shape().as_list()\n",
    "    n_elems = final_shape[1] * final_shape[2] * final_shape[3]\n",
    "    # if you're lazy,  n_elems = np.prod(final_shape[1:])\n",
    "    flat_a4 = tf.reshape(a4, [-1, n_elems])\n",
    "    # flat_a4: bs x 4*4*64\n",
    "    d4 = tf.nn.dropout(flat_a4, keep_prob)\n",
    "    with tf.variable_scope(\"fully_connected\"):\n",
    "        W = tf.get_variable(\n",
    "            \"weights\",\n",
    "            [n_elems, DESIRED_OUTPUT_SIZE],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable(\n",
    "            \"bias\",\n",
    "            [DESIRED_OUTPUT_SIZE],\n",
    "            initializer=tf.zeros_initializer())\n",
    "        logits = tf.matmul(d4, W) + b\n",
    "        # logits: Unscaled predictions. Notice we don't use an\n",
    "        # activation function here.\n",
    "        \n",
    "        # bs x DESIRED_OUTPUT_SIZE == [bs x 2] == shape of labels!\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits=None, labels=None):\n",
    "    with tf.name_scope(\"Eval\"):\n",
    "        elemwise_xent = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels, dim=-1)\n",
    "        avg_xent = tf.reduce_mean(elemwise_xent, axis=-1)\n",
    "    return avg_xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss, learning_rate=1e-4):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This constructs the graph. Running this cell twice without restarting the kernel will cause ``tf.get_variable`` to complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the pieces together.\n",
    "batch_size = 50\n",
    "iterations = 10000\n",
    "\n",
    "# Get a dataset, turn it into an iterator, return batch_image and\n",
    "# batch_label (no data in here yet, just graph building).\n",
    "train_dataset = input_pipeline(\n",
    "    batch_size, iterations, tfr_file=TFR_FILE)\n",
    "with tf.name_scope(\"Input\"):\n",
    "    train_iterator = train_dataset.make_initializable_iterator()\n",
    "    batch_image, batch_label = train_iterator.get_next()\n",
    "\n",
    "# Sanity check on the pipeline\n",
    "tf.summary.image(\"inputs\", batch_image, 1)\n",
    "\n",
    "# Sanity check on the keep prob\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "tf.summary.scalar(\"keep_prob\", keep_prob)\n",
    "\n",
    "# Run the batch of imgs through the convolutional stack\n",
    "logits = model(batch_image, keep_prob=keep_prob)\n",
    "\n",
    "# Get the loss\n",
    "loss_op = loss(logits=logits, labels=batch_label)\n",
    "\n",
    "# Monitor loss\n",
    "tf.summary.scalar(\"xent\", loss_op)\n",
    "\n",
    "# Train\n",
    "train_op = train(loss_op)\n",
    "\n",
    "# Magically merge all the summaries into one op.\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we handle a train/test split now?\n",
    "\n",
    "    train_dset = input_pipeline(\n",
    "        batch_size, iterations, tfr_file=TFR_TRAIN)\n",
    "    test_dset = input_pipeline(\n",
    "        batch_size, iterations, tfr_file=TFR_TEST)\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    # It really doesn't matter if you overshoot iterations.\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        train_iterator = train_dset.make_initializable_iterator()\n",
    "        test_iterator = test_dset.make_initializable_iterator()\n",
    "        batch_image, batch_label = tf.cond(\n",
    "            is_training,\n",
    "            lambda: train_iterator.get_next(),\n",
    "            lambda: test_iterator.get_next(),\n",
    "            name=\"choose_data\")\n",
    "            \n",
    "Admittedly, it's a little contrived, but I haven't found a better way yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some stuff on TensorBoard.\n",
    "\n",
    "    $ tensorboard --logdir=tb/tutorial\n",
    "    \n",
    "We aren't automatically clearing the TensorBoard file. If you want to run this twice, use the same tb file, and don't want to have jumbled graphs, DELETE tb/tutorial!\n",
    "\n",
    "After you're running ``tensorboard``, go to ``localhost:6006`` and check out the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [3.2054853]\n",
      "100 [0.86350244]\n",
      "200 [0.6849426]\n",
      "300 [0.68953967]\n",
      "400 [0.67173815]\n",
      "500 [0.6842258]\n",
      "600 [0.72459626]\n",
      "700 [0.67978317]\n",
      "800 [0.62469435]\n",
      "900 [0.68821692]\n",
      "1000 [0.67310441]\n",
      "1100 [0.68012029]\n",
      "1200 [0.73374277]\n",
      "1300 [0.65069425]\n",
      "1400 [0.67672628]\n",
      "1500 [0.68643713]\n",
      "1600 [0.68121016]\n",
      "1700 [0.64919662]\n",
      "1800 [0.68303972]\n",
      "1900 [0.68060791]\n",
      "2000 [0.70264405]\n",
      "2100 [0.67227471]\n",
      "2200 [0.65915924]\n",
      "2300 [0.69329268]\n",
      "2400 [0.68970263]\n",
      "2500 [0.68072993]\n",
      "2600 [0.64484537]\n",
      "2700 [0.67863578]\n",
      "2800 [0.71092546]\n",
      "2900 [0.69675964]\n",
      "3000 [0.68089616]\n",
      "3100 [0.67159635]\n",
      "3200 [0.69296592]\n",
      "3300 [0.71214175]\n",
      "3400 [0.69607812]\n",
      "3500 [0.70406282]\n",
      "3600 [0.69037366]\n",
      "3700 [0.69690186]\n",
      "3800 [0.68985528]\n",
      "3900 [0.63170135]\n",
      "4000 [0.67624885]\n",
      "4100 [0.76049638]\n",
      "4200 [0.7092613]\n",
      "4300 [0.68205917]\n",
      "4400 [0.68462998]\n",
      "4500 [0.6523453]\n",
      "4600 [0.65850502]\n",
      "4700 [0.61176008]\n",
      "4800 [0.67044312]\n",
      "4900 [0.68276715]\n",
      "5000 [0.66934198]\n",
      "5100 [0.67133242]\n",
      "5200 [0.68198776]\n",
      "5300 [0.71684754]\n",
      "5400 [0.67312533]\n",
      "5500 [0.6705699]\n",
      "5600 [0.68339354]\n",
      "5700 [0.74551529]\n",
      "5800 [0.64804125]\n",
      "5900 [0.64649588]\n",
      "6000 [0.65951097]\n",
      "6100 [0.6565851]\n",
      "6200 [0.69741559]\n",
      "6300 [0.67708635]\n",
      "6400 [0.6963985]\n",
      "6500 [0.70896971]\n",
      "6600 [0.67019236]\n",
      "6700 [0.66038299]\n",
      "6800 [0.69735765]\n",
      "6900 [0.68991745]\n",
      "7000 [0.67483687]\n",
      "7100 [0.6750192]\n",
      "7200 [0.67643446]\n",
      "7300 [0.70343089]\n",
      "7400 [0.66850615]\n",
      "7500 [0.67921448]\n",
      "7600 [0.69091767]\n",
      "7700 [0.66621065]\n",
      "7800 [0.67991775]\n",
      "7900 [0.64038825]\n",
      "8000 [0.63687027]\n",
      "8100 [0.67555541]\n",
      "8200 [0.73233569]\n",
      "8300 [0.67834425]\n",
      "8400 [0.68597257]\n",
      "8500 [0.67225367]\n",
      "8600 [0.68653226]\n",
      "8700 [0.6543054]\n",
      "8800 [0.67968488]\n",
      "8900 [0.63398403]\n",
      "9000 [0.67556214]\n",
      "9100 [0.72264594]\n",
      "9200 [0.66661423]\n",
      "9300 [0.7249431]\n",
      "9400 [0.69026929]\n",
      "9500 [0.70799792]\n",
      "9600 [0.67011774]\n",
      "9700 [0.71175784]\n",
      "9800 [0.69232291]\n",
      "9900 [0.65367395]\n",
      "10000 [0.70369565]\n"
     ]
    }
   ],
   "source": [
    "# Run the training.\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the tf.get_variable()s\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Create a TensorBoard writer (this line adds the graph dashboard)\n",
    "    train_writer = tf.summary.FileWriter(\"tb/tutorial\", sess.graph)\n",
    "    # INITIALIZE THE ITERATOR! START READING DATA OFF DISK!!\n",
    "    \n",
    "    sess.run(train_iterator.initializer)\n",
    "    # sess.run(test_iterator.initializer)\n",
    "\n",
    "    for epoch in range(iterations + 1):\n",
    "        check_in = epoch % 100 == 0\n",
    "        # test = epoch % 500 == 0\n",
    "        feed_dict = {keep_prob: 0.5}\n",
    "\n",
    "        # SPLIT:\n",
    "        # feed_dict = {keep_prob: 1 if test else 0.5,\n",
    "        #              is_training: not test}\n",
    "\n",
    "        # if not test:\n",
    "        _, summary = sess.run(\n",
    "            [train_op, summary_op], feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "        # elif test:\n",
    "        #     summary = sess.run([summary_op], feed_dict=feed_dict)\n",
    "\n",
    "        if check_in:\n",
    "            curr_loss = sess.run([loss_op], feed_dict=feed_dict)\n",
    "            print(epoch, curr_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
