{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A TensorFlow Input Pipeline Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to write Celeba images and male-female labels (available [here](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)) into a TFRecords file. Then, use the Dataset API to load the information into the graph. We will use a CNN to determine the gender of the image. We want TensorBoard visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylan/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread  # There are others that would work here.\n",
    "from cv2 import resize  # Again, others to choose from.\n",
    "import os  # Tools to read data off disk.\n",
    "import sklearn.model_selection as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Paths and Labels from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labeled_image_list(\n",
    "        img_dir=\"/media/dylan/DATA/img_align_celeba\",\n",
    "        label_txt_path=\"/media/dylan/DATA/list_attr_celeba.txt\"):\n",
    "    \"\"\"Read labeled images off disk.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: Path to folder containing all the images.\n",
    "        label_txt_path: Full path to annotation txt file.\n",
    "        \n",
    "    Returns:\n",
    "        A list of image paths for all images.\n",
    "        A list of one-hot lists [male?, female?] for all images.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the image paths.\n",
    "    img_filenames = os.listdir(img_dir)\n",
    "    # This is a list.\n",
    "    abs_img_paths = [os.path.join(img_dir, img_f) \n",
    "                     for img_f in img_filenames]\n",
    "    \n",
    "    # Get the labels by \"r\"eading the txt.\n",
    "    with open(label_txt_path, \"r\") as f:\n",
    "        img_fnames_and_lbls = f.read().splitlines()\n",
    "    # We will make a one-hot list-of-lists for all imgs.\n",
    "    labels = []\n",
    "    for fname_and_lbl in img_fnames_and_lbls[2:]:  # Skip 2 header rows\n",
    "        # Take everything after the .jpg part\n",
    "        lbl_str = fname_and_lbl.split(\".jpg\")[1]\n",
    "        lbl_str_split = lbl_str.split(\" \")\n",
    "        all_labels = [int(label) \n",
    "                      for label in lbl_str_split if label is not \"\"]\n",
    "        # Now we have a list of all 40 attributes,\n",
    "        # we want male info\n",
    "        is_male = all_labels[20] == 1\n",
    "        labels.append([int(is_male), int(not is_male)])\n",
    "    return abs_img_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make TFRecords\n",
    "We invoke the function we just defined to get all the image paths and labels. For each path and label, write the TFR format data into a file located at `tfr_file`.\n",
    "\n",
    "NOTE that in this example `TFRecordWriter` expects the `tfr` folder to **already exist** on **some systems** (for instance, I think `TFRecordWriter` can create the directory on Windows, but I know it cannot on Linux.) HOWEVER, it **creates** a file called `celeba_tutorial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tfr(\n",
    "        all_image_paths, all_labels, tfr_file=\"tfr/celeba_tutorial\"):\n",
    "    \"\"\"Write a TFR file inside `tfr_dir`.\n",
    "    \n",
    "    Get all the image paths and labels. Recall the labels come in\n",
    "    a list of lists of ints. FOR EACH IMAGE/LABEL, read the image, \n",
    "    do any preprocessing while image is still np.ndarray, \n",
    "    and convert into `bytes`. Then construct an `Example` object. \n",
    "    The `Example` object contains a `tf.train.Features` object\n",
    "    with a dictionary of `features`. We use helper functions\n",
    "    to convert our data into `Feature` types. Then, we write the image\n",
    "    and label to the file.\n",
    "    \n",
    "    COMMON GOTCHA: `bytes`, the raw encoding for the image, \n",
    "    is not a list type. However, `tf.train.Feature` needs a list!\n",
    "    That's why `_bytes_feature` turns `value` into a list. On the\n",
    "    other hand, each label **is** an integer list! So, we do **not** \n",
    "    need to make the argument of `_int64_list_feature` a list! \n",
    "    \n",
    "    \"\"\"\n",
    "    def _int64_list_feature(a_list):\n",
    "        return tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=a_list))\n",
    "\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    print(\"Writing TFR files.\")\n",
    "    writer = tf.python_io.TFRecordWriter(tfr_file)\n",
    "    for n, (path, label) in enumerate(zip(all_image_paths, all_labels)):\n",
    "        # n is only for a nice little status bar.\n",
    "        print(\"Writing file {}\\r\".format(n), end=\"\")\n",
    "        disk_im = imread(path)  # numpy ndarray, 218 x 178 x 3\n",
    "        resized_im = resize(disk_im, (128, 128))  # np, 128 x 128 x 3\n",
    "        raw_im = resized_im.tostring()  # <class 'bytes'>\n",
    "        # Construct an example proto-obj,\n",
    "        example = tf.train.Example(\n",
    "            # which wants a Features proto-obj,\n",
    "            features=tf.train.Features(\n",
    "                # which wants a dict.\n",
    "                feature={\n",
    "                    'image_raw': _bytes_feature(raw_im),\n",
    "                    'label': _int64_list_feature(label)\n",
    "        })) # close your example object\n",
    "        serialized = example.SerializeToString()\n",
    "        writer.write(serialized)\n",
    "    print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPLIT DIFFERENCE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to implement some simple overwrite protection\n",
    "# because it takes a while to write all of celeba, even to SSD.\n",
    "\n",
    "write_tfr = False  # force overwrite. Reset it while you're waiting :)\n",
    "TFR_TRAIN = \"/media/dylan/DATA/tfr/celeba_train\"\n",
    "TFR_TEST = \"/media/dylan/DATA/tfr/celeba_test\"\n",
    "\n",
    "if write_tfr or not os.path.isfile(TFR_TRAIN) or not os.path.isfile(TFR_TEST):\n",
    "    all_image_paths, all_labels = read_labeled_image_list()\n",
    "    tr_paths, te_paths, tr_lbls, te_lbls = sk.train_test_split(\n",
    "        all_image_paths, all_labels, test_size=0.2)\n",
    "    make_tfr(tr_paths, tr_lbls, tfr_file=TFR_TRAIN)\n",
    "    make_tfr(te_paths, te_lbls, tfr_file=TFR_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Now we have a data file to read. Let's get to the graph building. The first part of any graph is the data input pipeline. We're going to make\n",
    "an `input_pipeline` function. Why a function? If we want to use a train-test split, we want a dataset for both TFR files. We would call `input_pipeline` twice - once with `TFR_TRAIN` and again with `TFR_TEST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_pipeline(batch_size, epochs, tfr_file=\"tfr/celeba_tutorial\"):\n",
    "    dataset = tf.data.TFRecordDataset(tfr_file)\n",
    "\n",
    "    def parse_protocol_buffer(example_proto):\n",
    "        \"\"\"Read the TFR file into TENSORS! Read the bytes image\n",
    "        into a tf.string tensor and read the label into a\n",
    "        tf.int64 tensor!\"\"\"\n",
    "        features = {'image_raw': tf.FixedLenFeature((), tf.string),\n",
    "                    # NOTICE THE 2 HERE!\n",
    "                    'label': tf.FixedLenFeature((2), tf.int64)}\n",
    "        parsed_features = tf.parse_single_example(\n",
    "            example_proto, features)\n",
    "        return parsed_features['image_raw'], parsed_features['label']\n",
    "\n",
    "    # Apply the reading function to the dataset.\n",
    "    dataset = dataset.map(parse_protocol_buffer)\n",
    "\n",
    "    def convert_parsed_proto_to_input(image_string, label):\n",
    "        \"\"\"Convert that tf.string tensor with the raw image\n",
    "        into a tf.uint8 tensor (natural data-type for disk imgs).\n",
    "        Then restore the image shape. Finally, turn it into\n",
    "        a float so we can do real-valued math to it.\"\"\"\n",
    "        image_decoded = tf.decode_raw(image_string, tf.uint8)\n",
    "        image_resized = tf.reshape(image_decoded, (128, 128, 3))\n",
    "        image = tf.cast(image_resized, tf.float32)\n",
    "        # Reshape label as a sanity check, convert to a real number.\n",
    "        label = tf.reshape(label, [2])\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        # I usually put my image elements in [-1, 1]\n",
    "        return image * (2. /255) -1, label\n",
    "\n",
    "    # Apply the decoding function to the dataset.\n",
    "    dataset = dataset.map(convert_parsed_proto_to_input)\n",
    "    # Shuffle the dataset.\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    # Fill the dataset with this many examples & labels\n",
    "    dataset = dataset.repeat(batch_size*epochs)\n",
    "    # Collect `batch_size` num. of elements. Image and label\n",
    "    # tensors in the dataset change from [128 x 128 x 3] \n",
    "    # and [2] into [bs x 128 x 128 x 3] and [bs x 2].\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Fill the dataset with this many batches!\n",
    "    dataset = dataset.repeat(epochs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DESIRED_OUTPUT_SIZE = 2  # This is num labels per img. MALE and FEMALE\n",
    "\n",
    "def conv(imgs, filters_out, stride_size, kernel_size):\n",
    "    \"\"\"Simple 2D convolution helper function.\"\"\"\n",
    "    filters_in = imgs.get_shape().as_list()[3]\n",
    "    Kernel = tf.get_variable(\n",
    "        \"kernel\",\n",
    "        [kernel_size[0], kernel_size[1], filters_in, filters_out],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    Bias = tf.get_variable(\n",
    "        \"bias\",\n",
    "        [filters_out],\n",
    "        initializer=tf.zeros_initializer())\n",
    "    evidence = tf.nn.conv2d(\n",
    "        imgs,\n",
    "        Kernel,\n",
    "        strides=[1, stride_size[0], stride_size[1], 1],\n",
    "        padding=\"SAME\")\n",
    "    return evidence + Bias\n",
    "\n",
    "def model(image_tensor, keep_prob=0.5):\n",
    "    # Since conv uses tf.get_variable, we NEED tf.variable_scope.\n",
    "    # That tells tf.get_variable what variable to get, i.e. a new\n",
    "    # one or one that already exists. tf.variable_scope otherwise\n",
    "    # behaves similarly to tf.name_scope\n",
    "    with tf.variable_scope(\"layer1\"):\n",
    "        # input: bs x 128 x 128 x 3\n",
    "        z1 = conv(image_tensor, 64, (2, 2), (5, 5))\n",
    "        a1 = tf.nn.relu(z1)\n",
    "    # let's max-pool to hurry things up\n",
    "    m1 = tf.nn.max_pool(a1, [1, 2, 2, 1], [1, 2, 2, 1], \"SAME\")\n",
    "    with tf.variable_scope(\"layer2\"):\n",
    "        # input: bs x 32 x 32 x 64\n",
    "        z2 = conv(m1, 128, (2, 2), (5, 5))\n",
    "        a2 = tf.nn.relu(z2)\n",
    "    with tf.variable_scope(\"layer3\"):\n",
    "        # input: bs x 16 x 16 x 128\n",
    "        z3 = conv(a2, 256, (2, 2), (5, 5))\n",
    "        a3 = tf.nn.relu(z3)\n",
    "    with tf.variable_scope(\"layer4\"):\n",
    "        # input: bs x 8 x 8 x 256\n",
    "        z4 = conv(a3, 516, (2, 2), (5, 5))\n",
    "        a4 = tf.nn.relu(z4)\n",
    "        # output: bs x 4 x 4 x 516\n",
    "        \n",
    "    # Let's quit convolving.\n",
    "    final_shape = a4.get_shape().as_list()\n",
    "    n_elems = final_shape[1] * final_shape[2] * final_shape[3]\n",
    "    # if you're lazy,  n_elems = np.prod(final_shape[1:])\n",
    "    flat_a4 = tf.reshape(a4, [-1, n_elems])\n",
    "    # flat_a4: bs x 4*4*516\n",
    "\n",
    "    d4 = tf.nn.dropout(flat_a4, keep_prob)\n",
    "\n",
    "    with tf.variable_scope(\"fully_connected\"):\n",
    "        W = tf.get_variable(\n",
    "            \"weights\",\n",
    "            [n_elems, DESIRED_OUTPUT_SIZE],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b = tf.get_variable(\n",
    "            \"bias\",\n",
    "            [DESIRED_OUTPUT_SIZE],\n",
    "            initializer=tf.zeros_initializer())\n",
    "        logits = tf.matmul(d4, W) + b\n",
    "        # logits: Unscaled predictions. Notice we don't use an\n",
    "        # activation function here.\n",
    "        \n",
    "        # bs x DESIRED_OUTPUT_SIZE == [bs x 2] == shape of labels!\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits=None, labels=None):\n",
    "    with tf.name_scope(\"Eval\"):\n",
    "        elemwise_xent = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels, dim=-1)\n",
    "        avg_xent = tf.reduce_mean(elemwise_xent, axis=-1)\n",
    "    return avg_xent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss, learning_rate=1e-4):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(logits=None, labels=None):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This constructs the graph. Running this cell twice without restarting the kernel will cause ``tf.get_variable`` to complain.\n",
    "\n",
    "**SPLIT DIFFERENCE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the pieces together.\n",
    "batch_size = 100\n",
    "iterations = 100000\n",
    "\n",
    "# Get a dataset, turn it into an iterator, return batch_image and\n",
    "# batch_label (no data in here yet, just graph building).\n",
    "train_dset = input_pipeline(\n",
    "    batch_size, iterations, tfr_file=TFR_TRAIN)\n",
    "test_dset = input_pipeline(\n",
    "    batch_size, iterations, tfr_file=TFR_TEST)\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "# It really doesn't matter if you overshoot iterations.\n",
    "with tf.name_scope(\"Input\"):\n",
    "    train_iterator = train_dset.make_initializable_iterator()\n",
    "    test_iterator = test_dset.make_initializable_iterator()\n",
    "    batch_image, batch_label = tf.cond(\n",
    "        is_training,\n",
    "        lambda: train_iterator.get_next(),\n",
    "        lambda: test_iterator.get_next(),\n",
    "        name=\"choose_data\")\n",
    "\n",
    "# Sanity check on the pipeline\n",
    "tf.summary.image(\"inputs\", batch_image, 1)\n",
    "\n",
    "# Sanity check on the keep prob\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "tf.summary.scalar(\"keep_prob\", keep_prob)\n",
    "\n",
    "# Run the batch of imgs through the convolutional stack\n",
    "logits = model(batch_image, keep_prob=keep_prob)\n",
    "\n",
    "# Get the loss\n",
    "loss_op = loss(logits=logits, labels=batch_label)\n",
    "\n",
    "# Monitor loss\n",
    "tf.summary.scalar(\"xent\", loss_op)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy_op = accuracy(logits=logits, labels=batch_label)\n",
    "tf.summary.scalar(\"accuracy\", accuracy_op)\n",
    "\n",
    "# Train\n",
    "train_op = train(loss_op)\n",
    "\n",
    "# Magically merge all the summaries into one op.\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some stuff on TensorBoard.\n",
    "\n",
    "    $ tensorboard --logdir=tb/tutorial\n",
    "    \n",
    "We aren't automatically clearing the TensorBoard file. If you want to run this twice, use the same tb file, and don't want to have jumbled graphs, DELETE tb/tutorial!\n",
    "\n",
    "After you're running ``tensorboard``, go to ``localhost:6006`` and check out the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 38.1618 0.43\n",
      "Train 100 12.5005 0.52\n",
      "Train 200 6.41516 0.57\n",
      "Train 300 5.90774 0.47\n",
      "Train 400 4.43204 0.47\n",
      "Test 500 1.51768 0.52\n",
      "Train 600 2.59464 0.5\n",
      "Train 700 1.86606 0.47\n",
      "Train 800 1.13076 0.52\n",
      "Train 900 1.07851 0.51\n",
      "Test 1000 0.839415 0.44\n",
      "Train 1100 0.792712 0.58\n",
      "Train 1200 0.741112 0.57\n",
      "Train 1300 0.729485 0.57\n",
      "Train 1400 0.710758 0.58\n",
      "Test 1500 0.714962 0.54\n",
      "Train 1600 0.659878 0.65\n",
      "Train 1700 0.722128 0.56\n",
      "Train 1800 0.656512 0.63\n",
      "Train 1900 0.697288 0.55\n",
      "Test 2000 0.649102 0.66\n",
      "Train 2100 0.694829 0.55\n",
      "Train 2200 0.695174 0.56\n",
      "Train 2300 0.685592 0.62\n",
      "Train 2400 0.695074 0.54\n",
      "Test 2500 0.67985 0.57\n",
      "Train 2600 0.689453 0.55\n",
      "Train 2700 0.661591 0.58\n",
      "Train 2800 0.672648 0.6\n",
      "Train 2900 0.66605 0.66\n",
      "Test 3000 0.696323 0.55\n",
      "Train 3100 0.695796 0.53\n",
      "Train 3200 0.654394 0.64\n",
      "Train 3300 0.663981 0.6\n",
      "Train 3400 0.67936 0.6\n",
      "Test 3500 0.67199 0.63\n",
      "Train 3600 0.687693 0.56\n",
      "Train 3700 0.704253 0.52\n",
      "Train 3800 0.689241 0.56\n",
      "Train 3900 0.648314 0.66\n",
      "Test 4000 0.666651 0.66\n",
      "Train 4100 0.695758 0.56\n",
      "Train 4200 0.69627 0.51\n",
      "Train 4300 0.699714 0.54\n",
      "Train 4400 0.664198 0.64\n",
      "Test 4500 0.651354 0.67\n",
      "Train 4600 0.682743 0.58\n",
      "Train 4700 0.68479 0.57\n",
      "Train 4800 0.634596 0.71\n",
      "Train 4900 0.690297 0.57\n",
      "Test 5000 0.693395 0.53\n",
      "Train 5100 0.662671 0.67\n",
      "Train 5200 0.690971 0.51\n",
      "Train 5300 0.682651 0.59\n",
      "Train 5400 0.694063 0.54\n",
      "Test 5500 0.672576 0.63\n",
      "Train 5600 0.691167 0.54\n",
      "Train 5700 0.69456 0.54\n",
      "Train 5800 0.680595 0.6\n",
      "Train 5900 0.708696 0.54\n",
      "Test 6000 0.68924 0.57\n",
      "Train 6100 0.643368 0.69\n",
      "Train 6200 0.677216 0.58\n",
      "Train 6300 0.687136 0.54\n",
      "Train 6400 0.679339 0.6\n",
      "Test 6500 0.650585 0.65\n",
      "Train 6600 0.684115 0.54\n",
      "Train 6700 0.66962 0.6\n",
      "Train 6800 0.691763 0.51\n"
     ]
    }
   ],
   "source": [
    "# Run the training.\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the tf.get_variable()s\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Create a TensorBoard writer (this line adds the graph dashboard)\n",
    "    train_writer = tf.summary.FileWriter(\"tb/tutorial/train\", sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(\"tb/tutorial/test\", sess.graph)\n",
    "    # INITIALIZE THE ITERATOR! START READING DATA OFF DISK!!\n",
    "    \n",
    "    sess.run([train_iterator.initializer, test_iterator.initializer])\n",
    "\n",
    "    train_dict = {keep_prob: 0.5, is_training: True}\n",
    "    test_dict = {keep_prob: 1., is_training: False}\n",
    "\n",
    "    for epoch in range(iterations + 1):\n",
    "        check_in = epoch % 100 == 0\n",
    "        test = epoch % 500 == 0\n",
    "\n",
    "        if not test:\n",
    "            curr_loss, curr_acc, _, summary = sess.run(\n",
    "                [loss_op, accuracy_op, train_op, summary_op], feed_dict=train_dict)\n",
    "            train_writer.add_summary(summary, epoch)\n",
    "        elif test:\n",
    "            curr_loss, curr_acc, summary = sess.run([loss_op, accuracy_op, summary_op], feed_dict=test_dict)\n",
    "            test_writer.add_summary(summary, epoch)\n",
    "\n",
    "        if check_in:\n",
    "            print(\"Test\" if test else \"Train\", epoch, curr_loss, curr_acc)\n",
    "        \n",
    "    train_writer.close()\n",
    "    test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
